# ğŸ›³ï¸ Titanic Survival Prediction

This is my first end-to-end Machine Learning project using the famous Titanic dataset from Kaggle.  
The goal is to predict whether a passenger survived the Titanic disaster using various features like age, class, gender, etc.

---

## ğŸ“Š Project Overview

- âœ… Dataset: Titanic (from [Kaggle](https://www.kaggle.com/competitions/titanic))
- âœ… Model Used: **Logistic Regression**
- âœ… Accuracy Achieved: **81%**
- âœ… Tools & Libraries:
  - Python
  - Pandas, NumPy
  - Seaborn, Matplotlib
  - Scikit-learn (Logistic Regression, train/test split, metrics)

---

## ğŸ” Steps Followed

1. **Data Exploration & Cleaning**
   - Checked for missing values
   - Imputed missing Age values
   - Dropped or filled other missing features

2. **Visualization**
   - Used `countplot()` from Seaborn to analyze survival distribution
   - Explored features like `Sex`, `Pclass`, `Embarked`, etc.

3. **Feature Engineering**
   - Converted categorical features to numerical
   - Selected the most relevant columns for the model

4. **Model Training**
   - Trained a **Logistic Regression** model
   - Evaluated using accuracy score on validation set

---

## ğŸ“ˆ Result

- Achieved an **accuracy of 81%**
- Simple and explainable model
- Clean code and organized workflow

---

## ğŸ“‚ Files

- `titanic_survival_prediction.ipynb`: Main notebook with full code
- `README.md`: Project description and workflow

---

## ğŸš€ What's Next?

This is just the start of my ML journey.  
Next steps:
- Try more advanced models (Random Forest, XGBoost)
- Improve feature engineering
- Try out deep learning models in future projects

---

## ğŸ¤ Connect with Me

Feel free to reach out if you have feedback or suggestions!


