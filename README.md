# Titanic Survival Prediction

This is my first end-to-end Machine Learning project using the famous Titanic dataset from Kaggle.  
The goal is to predict whether a passenger survived the Titanic disaster using various features like age, class, gender, etc.

---

## Project Overview

- ‚úÖ Dataset: Titanic (from [Kaggle](https://www.kaggle.com/competitions/titanic))
- ‚úÖ Model Used: **Logistic Regression and descion tree**
- ‚úÖ Accuracy Achieved: **81%**
- ‚úÖ Tools & Libraries:
  - Python
  - Pandas, NumPy
  - Seaborn, Matplotlib
  - Scikit-learn (Logistic Regression, descion tree, train/test split, metrics)

---

## Steps Followed

1. **Data Exploration & Cleaning**
   - Checked for missing values
   - Imputed missing Age values
   - Dropped or filled other missing features

2. **Visualization**
   - Used `countplot()` from Seaborn to analyze survival distribution
   - Explored features like `Sex`, `Pclass`, `Embarked`, etc.

3. **Feature Engineering**
   - Converted categorical features to numerical
   - Selected the most relevant columns for the model

4. **Model Training**
   - Trained a **Logistic Regression and descion tree** model
   - Evaluated using accuracy score on validation set

---

## üìà Result

- Achieved an **accuracy of 81%**
- Simple and explainable model
- Clean code and organized workflow

---

## Files

- `titanic_survival_prediction.ipynb`: Main notebook with full code
- `README.md`: Project description and workflow

---

##  What's Next?

This is just the start of my ML journey.  
Next steps:
- Try more advanced models (Random Forest, XGBoost)
- Improve feature engineering
- Try out deep learning models in future projects

---

## ü§ù Connect with Me

Feel free to reach out if you have feedback or suggestions!


